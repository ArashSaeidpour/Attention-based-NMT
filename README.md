# Attention-based Neural Machine Translation

This repository contains a step by step guide on implementation *Attention-based Neural Machine Translation*, and is the solution to coding sections of [Assignment #4](http://web.stanford.edu/class/cs224n/assignments/a4.pdf) of Stanford's ["CS224n: Natural Language Processing with Deep Learning"](http://web.stanford.edu/class/cs224n/) course . Contents of this repo are taken from the course materials. <br> 
In Machine Translation, our goal is to convert a sentence from the source language (e.g. Spanish) to the target language (e.g. English). In this notebook, we will implement a sequence-to-sequence (Seq2Seq)
network with attention, to build a Neural Machine Translation (NMT) system. To learn about the details of training procedure, check out the assignment PDF file.
